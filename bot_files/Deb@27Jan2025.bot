{
 "name": "Deb",
 "model_engine": "claude-3-5-sonnet-20241022",
 "max_tokens": 4096,
 "temperature": 0.3,
 "role": "assistant",
 "role_description": "a friendly AI assistant",
 "conversation": {
  "content": "",
  "pending_results": [],
  "role": "empty",
  "tool_calls": [],
  "tool_results": [],
  "node_class": "AnthropicNode"
 },
 "system_message": "\n## About you\n- You are a diligent debugger named Deb (Deb Ug).     \n- You examine bugs carefully, gathering necessary context, before coming up with a diagnosis.\n- Then you ensure your diagnosis is correcy by recreating the bug.\n- Then you implement a fix and ensure the fix works on your recreation.\n- Your goal is to resolve all bugs, ensuring compliance with the requirements, and without adding unecessary complication (necessary complication is OK - KISS, YAGNI)\n\n## Tool Guidance\nYou use your tools flexibly, for instance, using powershell if you do not have a necessary tool. You should examine the available clis through powershell.\nIf you inadvertently corrupt a file, use powershell to delete it, and diff_edit with only additions (+at start of line) to rewrite.\n",
 "tool_handler": {
  "class": "bots.foundation.anthropic_bots.AnthropicToolHandler",
  "tools": [
   {
    "name": "diff_edit",
    "description": "Diff spec editing with flexible matching.\n\nUse when you need to make specific changes in text files.\n\nParameters:\n- file_path (str): Path to the file to modify\n- diff_spec (str): Diff-style specification of changes\n\nReturns:\nstr: Description of changes made/to be made or error message with context\n\nThe diff spec uses a simplified format:\n- Lines starting with '-' indicate text to be removed (no space after -)\n- Lines starting with '+' indicate text to be added (no space after +)\n- Blank lines separate different changes\n- Changes are applied in order:\n    - Text to be removed is matched\n    - Start of text is indexed\n    - Lines are removed\n    - Lines to add are inserted at index (If no lines were removed, index is set to EOF)\n\nDiff Spec Example: replace multiple sets of multiple lines:\n-def bad_function():\n-    return x+y\n+def good_function(x, y):\n+    return x+y\n\n-def print_nice():\n-    print('---')\n-    print(string)\n-    print('---')\n+def print_nice(string):\n+    sep = '---\\n'\n+    print(sep+string+sep)",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "diff_spec": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "diff_spec"
     ]
    }
   },
   {
    "name": "view",
    "description": "Display the contents of a file with line numbers.\n\nParameters:\n- file_path (str): The path to the file to be viewed.\n\nReturns:\nA string containing the file contents with line numbers.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      }
     },
     "required": [
      "file_path"
     ]
    }
   },
   {
    "name": "view_dir",
    "description": "Creates a summary of the directory structure starting from the given path, writing only files \nwith specified extensions. The output is written to a text file and returned as a string.\n\nParameters:\n- start_path (str): The root directory to start scanning from.\n- output_file (str): The name of the file to optionally write the directory structure to.\n- target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\nReturns:\nstr: A formatted string containing the directory structure, with each directory and file properly indented.\n\nExample output:\nmy_project/\n    module1/\n        script.py\n        README.md\n    module2/\n        utils.py",
    "input_schema": {
     "type": "object",
     "properties": {
      "start_path": {
       "type": "string"
      },
      "output_file": {
       "type": "string"
      },
      "target_extensions": {
       "type": "string"
      }
     },
     "required": []
    }
   },
   {
    "name": "execute_powershell",
    "description": "Executes PowerShell code in a stateless environment\n\nUse when you need to run PowerShell commands and capture their output. If\nyou have other tools available, you should use this as a fallback when the\nother tools fail. Coerces to utf-8 encoding.\n\nParameters:\n- code (str): PowerShell code to execute.\n- output_length_limit (int, optional): Maximum number of lines in the output.\n  If set, output exceeding this limit will be truncated. Default 60.\n\nReturns command output or an error message.",
    "input_schema": {
     "type": "object",
     "properties": {
      "code": {
       "type": "string"
      },
      "output_length_limit": {
       "type": "string"
      }
     },
     "required": [
      "code"
     ]
    }
   },
   {
    "name": "create_issue",
    "description": "Create a new issue in a repository.\n\nUse when you need to open a new issue in a specific repository.\n\nIf you have access to this tool, you may use it to report issues with itself\nand any other tools (tool failures only) to: https://github.com/benbuzz790/bots.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- title (str): The title of the issue.\n- body (str): The body content of the issue.\n\nReturns a JSON string containing the issue number and URL or an error message if unauthorized.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "title": {
       "type": "string"
      },
      "body": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "title",
      "body"
     ]
    }
   },
   {
    "name": "get_github_user_info",
    "description": "Get information about the authenticated user.\n\nUse when you need to retrieve details about the current user's GitHub account.\n\nParameters:\nNone\n\nReturns a JSON string containing user information (login, name, email, public repository count).",
    "input_schema": {
     "type": "object",
     "properties": {},
     "required": []
    }
   },
   {
    "name": "get_issue",
    "description": "Get detailed information about a specific issue.\n\nUse when you need to retrieve full details of a particular issue.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- issue_number (int): The number of the issue to retrieve.\n\nReturns a JSON string containing the issue details including title, body, state, labels, and comments count.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "issue_number": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "issue_number"
     ]
    }
   },
   {
    "name": "list_issues",
    "description": "List issues in a repository.\n\nUse when you need to get an overview of issues in a specific repository.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- state (str): The state of issues to list ('open', 'closed', or 'all', default is 'open').\n\nReturns a JSON string containing an array of issues with their number, title, and state.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "state": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name"
     ]
    }
   },
   {
    "name": "list_repositories",
    "description": "List all repositories for the authenticated user.\n\nUse when you need to get an overview of all repositories the user has access to.\n\nParameters:\nNone\n\nReturns a JSON string containing an array of repository full names (owner/repo).",
    "input_schema": {
     "type": "object",
     "properties": {},
     "required": []
    }
   },
   {
    "name": "update_issue",
    "description": "Update an existing issue.\n\nUse when you need to modify an issue's properties like title, body, or state.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- issue_number (int): The number of the issue to update.\n- **kwargs: Properties to update. Can include:\n    - title (str): New title for the issue\n    - body (str): New body content\n    - state (str): New state ('open' or 'closed')\n    - labels (list): List of label names\n\nReturns a JSON string containing the updated issue information.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "issue_number": {
       "type": "string"
      },
      "kwargs": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "issue_number",
      "kwargs"
     ]
    }
   }
  ],
  "requests": [],
  "results": [],
  "modules": {
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py": {
    "name": "bots.tools.code_tools",
    "source": "import os\nimport traceback\nimport textwrap\n\ndef view(file_path: str):\n    \"\"\"\n    Display the contents of a file with line numbers.\n\n    Parameters:\n    - file_path (str): The path to the file to be viewed.\n\n    Returns:\n    A string containing the file contents with line numbers.\n    \"\"\"\n    encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252', 'iso-8859-1'\n        ]\n    for encoding in encodings:\n        try:\n            with open(file_path, 'r', encoding=encoding) as file:\n                lines = file.readlines()\n            numbered_lines = [f'{i + 1}:{line.rstrip()}' for i, line in\n                enumerate(lines)]\n            return '\\n'.join(numbered_lines)\n        except UnicodeDecodeError:\n            continue\n        except Exception as e:\n            return f'Error: {str(e)}'\n    return (\n        f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n        )\n\n\ndef view_dir(start_path: str='.', output_file=None, target_extensions: str=\n    \"['py']\"):\n    \"\"\"\n    Creates a summary of the directory structure starting from the given path, writing only files \n    with specified extensions. The output is written to a text file and returned as a string.\n\n    Parameters:\n    - start_path (str): The root directory to start scanning from.\n    - output_file (str): The name of the file to optionally write the directory structure to.\n    - target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\n    Returns:\n    str: A formatted string containing the directory structure, with each directory and file properly indented.\n\n    Example output:\n    my_project/\n        module1/\n            script.py\n            README.md\n        module2/\n            utils.py\n    \"\"\"\n    extensions_list = [ext.strip().strip('\\'\"') for ext in\n        target_extensions.strip('[]').split(',')]\n    extensions_list = [('.' + ext if not ext.startswith('.') else ext) for\n        ext in extensions_list]\n    output_text = []\n    for root, dirs, files in os.walk(start_path):\n        has_py = False\n        for _, _, fs in os.walk(root):\n            if any(f.endswith(tuple(extensions_list)) for f in fs):\n                has_py = True\n                break\n        if has_py:\n            level = root.replace(start_path, '').count(os.sep)\n            indent = '    ' * level\n            line = f'{indent}{os.path.basename(root)}/'\n            output_text.append(line)\n            subindent = '    ' * (level + 1)\n            for file in files:\n                if file.endswith(tuple(extensions_list)):\n                    line = f'{subindent}{file}'\n                    output_text.append(line)\n    if output_file is not None:\n        with open(output_file, 'w') as file:\n            file.write(output_text)\n    return '\\n'.join(output_text)\n\n\ndef diff_edit(file_path: str, diff_spec: str):\n    \"\"\"Diff spec editing with flexible matching.\n\n    Use when you need to make specific changes in text files.\n\n    Parameters:\n    - file_path (str): Path to the file to modify\n    - diff_spec (str): Diff-style specification of changes\n\n    Returns:\n    str: Description of changes made/to be made or error message with context\n\n    The diff spec uses a simplified format:\n    - Lines starting with '-' indicate text to be removed (no space after -)\n    - Lines starting with '+' indicate text to be added (no space after +)\n    - Blank lines separate different changes\n    - Changes are applied in order:\n        - Text to be removed is matched\n        - Start of text is indexed\n        - Lines are removed\n        - Lines to add are inserted at index (If no lines were removed, index is set to EOF)\n\n    Diff Spec Example: replace multiple sets of multiple lines:\n    -def bad_function():\n    -    return x+y\n    +def good_function(x, y):\n    +    return x+y\n\n    -def print_nice():\n    -    print('---')\n    -    print(string)\n    -    print('---')\n    +def print_nice(string):\n    +    sep = '---\\\\n'\n    +    print(sep+string+sep)\n    \"\"\"\n    ignore_indentation: bool = True\n    context_lines: int = 2\n    try:\n        encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252',\n            'iso-8859-1']\n        content = None\n        used_encoding = 'utf-8'\n        if not os.path.exists(file_path):\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write('')\n            content = ''\n        else:\n            for encoding in encodings:\n                try:\n                    with open(file_path, 'r', encoding=encoding) as file:\n                        content = file.read()\n                        used_encoding = encoding\n                        break\n                except UnicodeDecodeError:\n                    continue\n        if content is None:\n            return (\n                f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n                )\n        if not diff_spec.strip():\n            return 'Error: No changes specified'\n        changes, errors = _parse_diff_spec(diff_spec=diff_spec)\n        if errors:\n            return 'Error parsing:' + '\\n'.join(errors)\n        original_lines = content.splitlines()\n        current_lines = original_lines.copy()\n        matched_changes = []\n        unmatched_changes = []\n        for remove, add in changes:\n            match_found, line_num, prev_indent, match_score, best_index = (\n                _find_matching_block(current_lines, remove, ignore_indentation)\n                )\n            if match_found:\n                indented_add = _adjust_indentation(add, prev_indent)\n                current_lines[line_num:line_num + len(remove)] = indented_add\n                matched_changes.append(('\\n'.join(remove), '\\n'.join(\n                    indented_add)))\n            else:\n                failure_context = ''\n                if match_score > 0:\n                    context = _get_context(current_lines, best_index,\n                        context_lines)\n                    failure_context = '\\nNearest partial match found around:\\n' + '\\n'.join(context) + f\"\"\"\nMatch score: {match_score:.2f}\"\"\"\n                    if ignore_indentation:\n                        failure_context += (\n                            '\\n(Note: matching with ignore_indentation=True)')\n                unmatched_changes.append(('\\n'.join(remove), '\\n'.join(add),\n                    failure_context))\n        if matched_changes:\n            new_content = '\\n'.join(current_lines)\n            if not new_content.endswith('\\n'):\n                new_content += '\\n'\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write(new_content)\n        report = []\n        report.append('Changes made:')\n        if matched_changes:\n            report.append(\n                f'\\nSuccessfully applied {len(matched_changes)} changes:')\n            for old, new in matched_changes:\n                report.append(f'\\nChanged:\\n{old}\\nTo:\\n{new}')\n        if unmatched_changes:\n            report.append(\n                f'\\nFailed to apply {len(unmatched_changes)} changes:')\n            for old, new, context in unmatched_changes:\n                report.append(f'\\nCould not find:\\n{old}')\n        return '\\n'.join(report) if report else 'No changes were applied'\n    except Exception as e:\n        return f'Error: {str(e)}\\n{traceback.format_exc()}'\n\n\ndef _parse_diff_spec(diff_spec: str):\n    changes = []\n    remove = []\n    add = []\n    errors = []\n    last_prefix = None\n    # Prevents the common LLM error of indenting, then adding +/-, then indenting again\n    diff_spec = textwrap.dedent(diff_spec)\n    for line in diff_spec.splitlines():\n        if not line:\n            if add:\n                changes.append((remove.copy(), add.copy()))\n                remove.clear()\n                add.clear()\n                last_prefix = None\n            continue\n        if line.startswith('-'):\n            last_prefix = '-'\n            content = line[1:]\n        elif line.startswith('+'):\n            last_prefix = '+'\n            content = line[1:]\n        elif last_prefix is not None:\n            content = line\n        else:\n            errors.append(\n                f'Error: First line in a change block \"{line}\" does not start with + or -.'\n                )\n            continue\n        if last_prefix == '-':\n            remove.append(content)\n        elif last_prefix == '+':\n            add.append(content)\n    if remove or add:\n        changes.append((remove, add))\n    if not changes and not errors:\n        errors.append('Error: No valid changes found in diff spec')\n    return changes, errors\n\n\ndef _find_matching_block(current_lines, remove_lines, ignore_indentation):\n    \"\"\"Find where a block of lines matches in the current file content.\n\n    Args:\n        current_lines: List of strings representing current file content\n        remove_lines: List of strings to find in the file\n        ignore_indentation: Whether to ignore leading whitespace when matching\n\n    Returns:\n        tuple (match_found: bool, line_num: int, indent: str, match_score: float, best_index: int)\n        where:\n        - match_found indicates if an exact match was found\n        - line_num is the line where the match starts (or best partial match)\n        - indent is the indentation to preserve\n        - match_score indicates quality of best partial match (0-1)\n        - best_index is the line number of best partial match\n    \"\"\"\n    if not remove_lines:\n        return True, len(current_lines), '', 1.0, len(current_lines)\n    for i in range(len(current_lines) - len(remove_lines) + 1):\n        current_block = current_lines[i:i + len(remove_lines)]\n        if ignore_indentation:\n            match = all(c.strip() == o.strip() for c, o in zip(\n                current_block, remove_lines))\n        else:\n            match = all(c == o for c, o in zip(current_block, remove_lines))\n        if match:\n            return True, i, _get_indentation(current_lines[i]), 1.0, i\n    best_match_score = 0\n    best_match_index = 0\n    for i in range(len(current_lines) - len(remove_lines) + 1):\n        current_block = current_lines[i:i + len(remove_lines)]\n        match_score = _calculate_block_match_score(current_block,\n            remove_lines, ignore_indentation)\n        if match_score > best_match_score:\n            best_match_score = match_score\n            best_match_index = i\n    return False, best_match_index, _get_indentation(current_lines[\n        best_match_index]), best_match_score, best_match_index\n\n\ndef _get_indentation(line):\n    \"\"\"Extract the leading whitespace from a line.\"\"\"\n    return line[:len(line) - len(line.lstrip())]\n\n\ndef _adjust_indentation(lines, target_indent):\n    \"\"\"Adjust indentation of a block of lines to match target_indent.\"\"\"\n    if not lines:\n        return lines\n    non_empty_lines = [l for l in lines if l.strip()]\n    if not non_empty_lines:\n        return lines\n    min_indent = min(len(_get_indentation(l)) for l in non_empty_lines)\n    adjusted = []\n    for line in lines:\n        if not line.strip():\n            adjusted.append(line)\n        else:\n            stripped = line[min_indent:]\n            adjusted.append(target_indent + stripped)\n    return adjusted\n\n\ndef _get_context(lines, center_idx, context_size):\n    \"\"\"Get context lines around an index with line numbers.\"\"\"\n    start = max(0, center_idx - context_size)\n    end = min(len(lines), center_idx + context_size + 1)\n    return [f'{i + 1}: {line}' for i, line in enumerate(lines[start:end],\n        start)]\n\n\ndef _calculate_block_match_score(current_block, old_lines, ignore_indentation):\n    \"\"\"Calculate how well two blocks match, returning a score and matching line indices.\"\"\"\n    if ignore_indentation:\n        current_joined = ' '.join(l.strip() for l in current_block)\n        old_joined = ' '.join(l.strip() for l in old_lines)\n        current_stripped = [c.strip() for c in current_block]\n        old_stripped = [o.strip() for o in old_lines]\n    else:\n        current_joined = ' '.join(current_block)\n        old_joined = ' '.join(old_lines)\n        current_stripped = current_block\n        old_stripped = old_lines\n    exact_matches = sum(1 for c, o in zip(current_stripped, old_stripped) if\n        c == o)\n    if current_joined == old_joined:\n        return len(current_block) * 3\n    c_words = set(current_joined.split())\n    o_words = set(old_joined.split())\n    word_matches = len(c_words.intersection(o_words))\n    partial_score = 0\n    if word_matches > 0:\n        partial_score = word_matches / max(len(c_words), len(o_words))\n        if word_matches == len(c_words) and word_matches == len(o_words):\n            partial_score *= 2\n    total_score = exact_matches * 2 + partial_score\n    return total_score\n\n\ndef _has_line_number_prefix(line: str) ->bool:\n    \"\"\"Check if a string starts with a line number format (e.g., '123:' or '  123:')\n    Args:\n        line (str): The line to check\n    Returns:\n        bool: True if the line starts with a number followed by a colon\n    \"\"\"\n    stripped = line.lstrip()\n    if ':' not in stripped:\n        return False\n    prefix = stripped.split(':', 1)[0]\n    try:\n        int(prefix)\n        return True\n    except ValueError:\n        return False\n\n\ndef _strip_line_number(line: str) ->str:\n    \"\"\"Remove line number prefix if present (e.g., '123:content' or '  123:content' becomes 'content')\n    Preserves any leading whitespace before the line number.\n    Args:\n        line (str): The line to process\n    Returns:\n        str: The line with any line number prefix removed\n    \"\"\"\n    if not _has_line_number_prefix(line):\n        return line\n    whitespace = line[:len(line) - len(line.lstrip())]\n    stripped = line.lstrip()\n    content = stripped.split(':', 1)[1]\n    return whitespace + content",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
    "code_hash": "8c07ce3256cb0bf78379eb580e29fe25"
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py": {
    "name": "bots.tools.terminal_tools",
    "source": "import os, subprocess, traceback\nfrom typing import List\n\ndef execute_powershell(code: str, output_length_limit: str='60'):\n   \"\"\"\n   Executes PowerShell code in a stateless environment\n\n   Use when you need to run PowerShell commands and capture their output. If\n   you have other tools available, you should use this as a fallback when the\n   other tools fail. Coerces to utf-8 encoding.\n\n   Parameters:\n   - code (str): PowerShell code to execute.\n   - output_length_limit (int, optional): Maximum number of lines in the output.\n     If set, output exceeding this limit will be truncated. Default 60.\n\n   Returns command output or an error message.\n   \"\"\"\n\n   def _process_error(error):\n       error_message = f'Tool Failed: {str(error)}\\n'\n       error_message += (\n           f\"Traceback:\\n{''.join(traceback.format_tb(error.__traceback__))}\")\n       return error_message\n\n   output = ''\n   try:\n       # Wrap code to ensure proper utf-8 encoding\n       wrapped_code = f'chcp 65001 > $null; {code}'\n\n       process = subprocess.Popen(\n           ['powershell', '-Command', wrapped_code],\n           stdout=subprocess.PIPE,\n           stderr=subprocess.PIPE,\n           text=True, \n           encoding='utf-8'\n       )\n\n       stdout, stderr = process.communicate(timeout=300)\n       output = stdout\n       if stderr:\n           output += stderr\n\n   except subprocess.TimeoutExpired as e:\n       process.kill()\n       output += 'Error: Command execution timed out after 300 seconds.'\n   except Exception as e:\n       output += _process_error(e)\n\n   # Handle output length limiting\n   if output_length_limit is not None and output:\n       output_length_limit = int(output_length_limit)\n       lines = output.splitlines()\n       if len(lines) > output_length_limit:\n           truncated_lines = lines[:output_length_limit]\n           lines_omitted = len(lines) - output_length_limit\n           truncated_output = '\\n'.join(truncated_lines)\n           # Save full output to file\n           output_file = os.path.join(os.getcwd(), 'powershell_full_output.txt')\n           with open(output_file, 'w', encoding='utf-8') as f:\n               f.write(output)\n           truncated_output += (\n               f'\\n\\n{lines_omitted} lines omitted due to length limit. Full output saved to {output_file}')\n           return truncated_output\n\n   return output",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py",
    "code_hash": "298fbe7927f9824aabe2f40cd5533656"
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py": {
    "name": "bots.tools.github_tools",
    "source": "import json\nfrom ghapi.all import GhApi\nimport base64\nimport os\n\n\ndef _setup():\n    \"\"\"\n    Internal function to set up the GitHub API client.\n\n    This function looks for a GitHub token in the environment variables.\n    It checks for GITHUB_TOKEN first, then GITHUB_ACCESS_TOKEN.\n    If neither is found, it raises an exception.\n\n    Returns:\n    GhApi: An instance of the GitHub API client.\n\n    Raises:\n    ValueError: If neither GITHUB_TOKEN nor GITHUB_ACCESS_TOKEN environment variable is set.\n    \"\"\"\n    token = os.environ.get('GITHUB_TOKEN') or os.environ.get(\n        'GITHUB_ACCESS_TOKEN')\n    if not token:\n        raise ValueError(\n            'Neither GITHUB_TOKEN nor GITHUB_ACCESS_TOKEN environment variable is set. Please set one of them with your GitHub Personal Access Token.'\n            )\n    return GhApi(token=token)\n\n\ndef list_repositories():\n    \"\"\"\n    List all repositories for the authenticated user.\n\n    Use when you need to get an overview of all repositories the user has access to.\n\n    Parameters:\n    None\n\n    Returns a JSON string containing an array of repository full names (owner/repo).\n    \"\"\"\n    try:\n        api = _setup()\n        repos = api.repos.list_for_authenticated_user()\n        return json.dumps([repo.full_name for repo in repos])\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef list_issues(repo_full_name, state='open'):\n    \"\"\"\n    List issues in a repository.\n\n    Use when you need to get an overview of issues in a specific repository.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - state (str): The state of issues to list ('open', 'closed', or 'all', default is 'open').\n\n    Returns a JSON string containing an array of issues with their number, title, and state.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issues = api.issues.list_for_repo(owner=owner, repo=repo, state=state)\n        return json.dumps([{'number': issue.number, 'title': issue.title,\n            'state': issue.state} for issue in issues])\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef create_issue(repo_full_name, title, body):\n    \"\"\"\n    Create a new issue in a repository.\n\n    Use when you need to open a new issue in a specific repository.\n\n    If you have access to this tool, you may use it to report issues with itself\n    and any other tools (tool failures only) to: https://github.com/benbuzz790/bots.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - title (str): The title of the issue.\n    - body (str): The body content of the issue.\n\n    Returns a JSON string containing the issue number and URL or an error message if unauthorized.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        repos = json.loads(list_repositories())\n        if not any(repo == repo_full_name for repo in repos):\n            return (\n                f'Error: Not authorized to create issues in {repo_full_name}. Repository must be in your list of accessible repositories.'\n                )\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.create(owner=owner, repo=repo, title=title, body\n            =body)\n        return json.dumps({'number': issue.number, 'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef get_issue(repo_full_name, issue_number):\n    \"\"\"\n    Get detailed information about a specific issue.\n\n    Use when you need to retrieve full details of a particular issue.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - issue_number (int): The number of the issue to retrieve.\n\n    Returns a JSON string containing the issue details including title, body, state, labels, and comments count.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.get(owner=owner, repo=repo, issue_number=\n            issue_number)\n        return json.dumps({'number': issue.number, 'title': issue.title,\n            'body': issue.body, 'state': issue.state, 'labels': [label.name for\n            label in issue.labels], 'comments': issue.comments,\n            'created_at': issue.created_at, 'updated_at': issue.updated_at,\n            'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef update_issue(repo_full_name, issue_number, **kwargs):\n    \"\"\"\n    Update an existing issue.\n\n    Use when you need to modify an issue's properties like title, body, or state.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - issue_number (int): The number of the issue to update.\n    - **kwargs: Properties to update. Can include:\n        - title (str): New title for the issue\n        - body (str): New body content\n        - state (str): New state ('open' or 'closed')\n        - labels (list): List of label names\n\n    Returns a JSON string containing the updated issue information.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.update(owner=owner, repo=repo, issue_number=\n            issue_number, **kwargs)\n        return json.dumps({'number': issue.number, 'title': issue.title,\n            'state': issue.state, 'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef get_github_user_info():\n    \"\"\"\n    Get information about the authenticated user.\n\n    Use when you need to retrieve details about the current user's GitHub account.\n\n    Parameters:\n    None\n\n    Returns a JSON string containing user information (login, name, email, public repository count).\n    \"\"\"\n    try:\n        api = _setup()\n        user = api.users.get_authenticated()\n        return json.dumps({'login': user.login, 'name': user.name, 'email':\n            user.email, 'public_repos': user.public_repos})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef _normalize_repo_name(repo_full_name):\n    \"\"\"\n    Helper function to normalize repository name input.\n    Handles both string format and JSON object format.\n\n    Parameters:\n    - repo_full_name: Can be one of:\n        - string in format \"owner/repo\"\n        - dict with 'repo' key\n        - JSON string representing dict with 'repo' key\n\n    Returns:\n    str: Normalized repository name in \"owner/repo\" format\n    \"\"\"\n    if isinstance(repo_full_name, dict):\n        if not repo_full_name:\n            raise ValueError('Empty dictionary provided')\n        if 'repo' not in repo_full_name:\n            raise ValueError(\"Dictionary input must contain 'repo' key\")\n        repo_name = repo_full_name['repo']\n        if not isinstance(repo_name, str):\n            raise ValueError('Repository name must be a string')\n        if '/' not in repo_name:\n            raise ValueError(\"Repository name must be in 'owner/repo' format\")\n        return repo_name\n    if not isinstance(repo_full_name, str):\n        raise ValueError('Input must be a string or dictionary')\n    if repo_full_name.strip().startswith('{'):\n        try:\n            parsed = json.loads(repo_full_name)\n            if not isinstance(parsed, dict):\n                raise ValueError('Parsed JSON must be a dictionary')\n            if 'repo' not in parsed:\n                raise ValueError(\n                    \"Parsed JSON dictionary must contain 'repo' key\")\n            repo_name = parsed['repo']\n            if not isinstance(repo_name, str):\n                raise ValueError('Repository name must be a string')\n            if '/' not in repo_name:\n                raise ValueError(\n                    \"Repository name must be in 'owner/repo' format\")\n            return repo_name\n        except json.JSONDecodeError:\n            pass\n    if not repo_full_name:\n        raise ValueError('Empty string provided')\n    if '/' not in repo_full_name:\n        raise ValueError(\"Repository name must be in 'owner/repo' format\")\n    owner, repo = repo_full_name.split('/')\n    if not owner or not repo:\n        raise ValueError('Both owner and repo must be non-empty')\n    return repo_full_name",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
    "code_hash": "69ff2574590a24a7b59d34d47c1057c8"
   }
  },
  "function_paths": {
   "diff_edit": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "view": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "view_dir": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "execute_powershell": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py",
   "create_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "get_github_user_info": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "get_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "list_issues": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "list_repositories": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "update_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py"
  }
 },
 "autosave": false,
 "tool_path": "<module 'bots.tools.github_tools' from 'C:\\\\Users\\\\benbu\\\\Code\\\\llm-utilities-git\\\\bots\\\\bots\\\\tools\\\\github_tools.py'>",
 "bot_class": "AnthropicBot"
}