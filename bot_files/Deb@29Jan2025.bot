{
 "name": "Deb",
 "model_engine": "claude-3-5-sonnet-20241022",
 "max_tokens": 4096,
 "temperature": 0.3,
 "role": "assistant",
 "role_description": "a friendly AI assistant",
 "conversation": {
  "content": "",
  "pending_results": [],
  "role": "empty",
  "tool_calls": [],
  "tool_results": [],
  "node_class": "AnthropicNode"
 },
 "system_message": "\n## About you\n- You are a diligent debugger named Deb (Deb Ug).     \n- You examine bugs carefully, gathering necessary context, before coming up with a diagnosis.\n- Then you ensure your diagnosis is correcy by recreating the bug.\n- Then you implement a fix and ensure the fix works on your recreation.\n- Your goal is to resolve all bugs, ensuring compliance with the requirements, and without adding unecessary complication (necessary complication is OK - KISS, YAGNI)\n\n## Tool Guidance\nYou use your tools flexibly, for instance, using powershell if you do not have a necessary tool. You should examine the available clis through powershell.\nIf you inadvertently corrupt a file, use powershell to delete it, and diff_edit with only additions (+at start of line) to rewrite.\n",
 "tool_handler": {
  "class": "bots.foundation.anthropic_bots.AnthropicToolHandler",
  "tools": [
   {
    "name": "diff_edit",
    "description": "Diff spec editing with flexible matching.\n\nUse when you need to make specific changes in text files.\n\nParameters:\n- file_path (str): Path to the file to modify\n- diff_spec (str): Diff-style specification of changes\n\nReturns:\nstr: Description of changes made/to be made or error message with context\n\nThe diff spec uses a simplified format:\n- Lines starting with '-' indicate text to be removed (no space after -)\n- Lines starting with '+' indicate text to be added (no space after +)\n- Blank lines separate different changes\n- Changes are applied in order:\n    - Text to be removed is matched\n    - Start of text is indexed\n    - Lines are removed\n    - Lines to add are inserted at index (If no lines were removed, index is set to EOF)\n\nDiff Spec Example: replace multiple sets of multiple lines:\n-def bad_function():\n-    return x+y\n+def good_function(x, y):\n+    return x+y\n\n-def print_nice():\n-    print('---')\n-    print(string)\n-    print('---')\n+def print_nice(string):\n+    sep = '---\\n'\n+    print(sep+string+sep)",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "diff_spec": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "diff_spec"
     ]
    }
   },
   {
    "name": "view",
    "description": "Display the contents of a file with line numbers.\n\nParameters:\n- file_path (str): The path to the file to be viewed.\n\nReturns:\nA string containing the file contents with line numbers.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      }
     },
     "required": [
      "file_path"
     ]
    }
   },
   {
    "name": "view_dir",
    "description": "Creates a summary of the directory structure starting from the given path, writing only files \nwith specified extensions. The output is written to a text file and returned as a string.\n\nParameters:\n- start_path (str): The root directory to start scanning from.\n- output_file (str): The name of the file to optionally write the directory structure to.\n- target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\nReturns:\nstr: A formatted string containing the directory structure, with each directory and file properly indented.\n\nExample output:\nmy_project/\n    module1/\n        script.py\n        README.md\n    module2/\n        utils.py",
    "input_schema": {
     "type": "object",
     "properties": {
      "start_path": {
       "type": "string"
      },
      "output_file": {
       "type": "string"
      },
      "target_extensions": {
       "type": "string"
      }
     },
     "required": []
    }
   },
   {
    "name": "execute_powershell",
    "description": "Executes PowerShell code in a stateless environment\n\nUse when you need to run PowerShell commands and capture their output. If\nyou have other tools available, you should use this as a fallback when the\nother tools fail. Coerces to utf-8 encoding.\n\nParameters:\n- code (str): PowerShell code to execute.\n- output_length_limit (int, optional): Maximum number of lines in the output.\n  If set, output exceeding this limit will be truncated. Default 60.\n\nReturns command output or an error message.",
    "input_schema": {
     "type": "object",
     "properties": {
      "code": {
       "type": "string"
      },
      "output_length_limit": {
       "type": "string"
      }
     },
     "required": [
      "code"
     ]
    }
   },
   {
    "name": "create_issue",
    "description": "Create a new issue in a repository.\n\nUse when you need to open a new issue in a specific repository.\n\nIf you have access to this tool, you may use it to report issues with itself\nand any other tools (tool failures only) to: https://github.com/benbuzz790/bots.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- title (str): The title of the issue.\n- body (str): The body content of the issue.\n\nReturns a JSON string containing the issue number and URL or an error message if unauthorized.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "title": {
       "type": "string"
      },
      "body": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "title",
      "body"
     ]
    }
   },
   {
    "name": "get_github_user_info",
    "description": "Get information about the authenticated user.\n\nUse when you need to retrieve details about the current user's GitHub account.\n\nParameters:\nNone\n\nReturns a JSON string containing user information (login, name, email, public repository count).",
    "input_schema": {
     "type": "object",
     "properties": {},
     "required": []
    }
   },
   {
    "name": "get_issue",
    "description": "Get detailed information about a specific issue.\n\nUse when you need to retrieve full details of a particular issue.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- issue_number (int): The number of the issue to retrieve.\n\nReturns a JSON string containing the issue details including title, body, state, labels, and comments count.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "issue_number": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "issue_number"
     ]
    }
   },
   {
    "name": "list_issues",
    "description": "List issues in a repository.\n\nUse when you need to get an overview of issues in a specific repository.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- state (str): The state of issues to list ('open', 'closed', or 'all', default is 'open').\n\nReturns a JSON string containing an array of issues with their number, title, and state.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "state": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name"
     ]
    }
   },
   {
    "name": "list_repositories",
    "description": "List all repositories for the authenticated user.\n\nUse when you need to get an overview of all repositories the user has access to.\n\nParameters:\nNone\n\nReturns a JSON string containing an array of repository full names (owner/repo).",
    "input_schema": {
     "type": "object",
     "properties": {},
     "required": []
    }
   },
   {
    "name": "update_issue",
    "description": "Update an existing issue.\n\nUse when you need to modify an issue's properties like title, body, or state.\n\nParameters:\n- repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n- issue_number (int): The number of the issue to update.\n- **kwargs: Properties to update. Can include:\n    - title (str): New title for the issue\n    - body (str): New body content\n    - state (str): New state ('open' or 'closed')\n    - labels (list): List of label names\n\nReturns a JSON string containing the updated issue information.",
    "input_schema": {
     "type": "object",
     "properties": {
      "repo_full_name": {
       "type": "string"
      },
      "issue_number": {
       "type": "string"
      },
      "kwargs": {
       "type": "string"
      }
     },
     "required": [
      "repo_full_name",
      "issue_number",
      "kwargs"
     ]
    }
   },
   {
    "name": "replace_class",
    "description": "Replaces a class definition in a file with a new class definition.\nCreates the file if it doesn't exist.\n\nParameters:\n- file_path (str): The path to the file to modify\n- new_class_def (str): The new class definition\n- old_class_name (str, optional): The name of the class to replace\n\nReturns a confirmation message or an error message.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "new_class_def": {
       "type": "string"
      },
      "old_class_name": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "new_class_def"
     ]
    }
   },
   {
    "name": "replace_function",
    "description": "Replaces one or more function definitions in a file with new function definitions.\nCreates the file if it doesn't exist.\n\nParameters:\n- file_path (str): The path to the file to modify\n- new_function_def (str): One or more function definitions as a string\n- class_name (str, optional): If provided, only replace functions within this class\n\nReturns a confirmation message or an error message.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "new_function_def": {
       "type": "string"
      },
      "class_name": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "new_function_def"
     ]
    }
   }
  ],
  "requests": [],
  "results": [],
  "modules": {
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py": {
    "name": "bots.tools.code_tools",
    "source": "import os\nimport traceback\nimport textwrap\n\ndef view(file_path: str):\n    \"\"\"\n    Display the contents of a file with line numbers.\n\n    Parameters:\n    - file_path (str): The path to the file to be viewed.\n\n    Returns:\n    A string containing the file contents with line numbers.\n    \"\"\"\n    encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252', 'iso-8859-1'\n        ]\n    for encoding in encodings:\n        try:\n            with open(file_path, 'r', encoding=encoding) as file:\n                lines = file.readlines()\n            numbered_lines = [f'{i + 1}:{line.rstrip()}' for i, line in\n                enumerate(lines)]\n            return '\\n'.join(numbered_lines)\n        except UnicodeDecodeError:\n            continue\n        except Exception as e:\n            return f'Error: {str(e)}'\n    return (\n        f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n        )\n\n\ndef view_dir(start_path: str='.', output_file=None, target_extensions: str=\n    \"['py']\"):\n    \"\"\"\n    Creates a summary of the directory structure starting from the given path, writing only files \n    with specified extensions. The output is written to a text file and returned as a string.\n\n    Parameters:\n    - start_path (str): The root directory to start scanning from.\n    - output_file (str): The name of the file to optionally write the directory structure to.\n    - target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\n    Returns:\n    str: A formatted string containing the directory structure, with each directory and file properly indented.\n\n    Example output:\n    my_project/\n        module1/\n            script.py\n            README.md\n        module2/\n            utils.py\n    \"\"\"\n    extensions_list = [ext.strip().strip('\\'\"') for ext in\n        target_extensions.strip('[]').split(',')]\n    extensions_list = [('.' + ext if not ext.startswith('.') else ext) for\n        ext in extensions_list]\n    output_text = []\n    for root, dirs, files in os.walk(start_path):\n        has_py = False\n        for _, _, fs in os.walk(root):\n            if any(f.endswith(tuple(extensions_list)) for f in fs):\n                has_py = True\n                break\n        if has_py:\n            level = root.replace(start_path, '').count(os.sep)\n            indent = '    ' * level\n            line = f'{indent}{os.path.basename(root)}/'\n            output_text.append(line)\n            subindent = '    ' * (level + 1)\n            for file in files:\n                if file.endswith(tuple(extensions_list)):\n                    line = f'{subindent}{file}'\n                    output_text.append(line)\n    if output_file is not None:\n        with open(output_file, 'w') as file:\n            file.write(output_text)\n    return '\\n'.join(output_text)\n\n\ndef diff_edit(file_path: str, diff_spec: str):\n    \"\"\"Diff spec editing with flexible matching.\n\n    Use when you need to make specific changes in text files.\n\n    Parameters:\n    - file_path (str): Path to the file to modify\n    - diff_spec (str): Diff-style specification of changes\n\n    Returns:\n    str: Description of changes made/to be made or error message with context\n\n    The diff spec uses a simplified format:\n    - Lines starting with '-' indicate text to be removed (no space after -)\n    - Lines starting with '+' indicate text to be added (no space after +)\n    - Blank lines separate different changes\n    - Changes are applied in order:\n        - Text to be removed is matched\n        - Start of text is indexed\n        - Lines are removed\n        - Lines to add are inserted at index (If no lines were removed, index is set to EOF)\n\n    Diff Spec Example: replace multiple sets of multiple lines:\n    -def bad_function():\n    -    return x+y\n    +def good_function(x, y):\n    +    return x+y\n\n    -def print_nice():\n    -    print('---')\n    -    print(string)\n    -    print('---')\n    +def print_nice(string):\n    +    sep = '---\\\\n'\n    +    print(sep+string+sep)\n    \"\"\"\n    ignore_indentation: bool = True\n    context_lines: int = 2\n    try:\n        encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252',\n            'iso-8859-1']\n        content = None\n        used_encoding = 'utf-8'\n        if not os.path.exists(file_path):\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write('')\n            content = ''\n        else:\n            for encoding in encodings:\n                try:\n                    with open(file_path, 'r', encoding=encoding) as file:\n                        content = file.read()\n                        used_encoding = encoding\n                        break\n                except UnicodeDecodeError:\n                    continue\n        if content is None:\n            return (\n                f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n                )\n        if not diff_spec.strip():\n            return 'Error: No changes specified'\n        changes, errors = _parse_diff_spec(diff_spec=diff_spec)\n        if errors:\n            return 'Error parsing:' + '\\n'.join(errors)\n        original_lines = content.splitlines()\n        current_lines = original_lines.copy()\n        matched_changes = []\n        unmatched_changes = []\n        for remove, add in changes:\n            match_found, line_num, prev_indent, match_score, best_index = (\n                _find_matching_block(current_lines, remove, ignore_indentation)\n                )\n            if match_found:\n                indented_add = _adjust_indentation(add, prev_indent)\n                current_lines[line_num:line_num + len(remove)] = indented_add\n                matched_changes.append(('\\n'.join(remove), '\\n'.join(\n                    indented_add)))\n            else:\n                failure_context = ''\n                if match_score > 0:\n                    context = _get_context(current_lines, best_index,\n                        context_lines)\n                    failure_context = '\\nNearest partial match found around:\\n' + '\\n'.join(context) + f\"\"\"\nMatch score: {match_score:.2f}\"\"\"\n                    if ignore_indentation:\n                        failure_context += (\n                            '\\n(Note: matching with ignore_indentation=True)')\n                unmatched_changes.append(('\\n'.join(remove), '\\n'.join(add),\n                    failure_context))\n        if matched_changes:\n            new_content = '\\n'.join(current_lines)\n            if not new_content.endswith('\\n'):\n                new_content += '\\n'\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write(new_content)\n        report = []\n        report.append('Changes made:')\n        if matched_changes:\n            report.append(\n                f'\\nSuccessfully applied {len(matched_changes)} changes:')\n            for old, new in matched_changes:\n                report.append(f'\\nChanged:\\n{old}\\nTo:\\n{new}')\n        if unmatched_changes:\n            report.append(\n                f'\\nFailed to apply {len(unmatched_changes)} changes:')\n            for old, new, context in unmatched_changes:\n                report.append(f'\\nCould not find:\\n{old}')\n        return '\\n'.join(report) if report else 'No changes were applied'\n    except Exception as e:\n        return f'Error: {str(e)}\\n{traceback.format_exc()}'\n\n\ndef _parse_diff_spec(diff_spec: str):\n    changes = []\n    remove = []\n    add = []\n    errors = []\n    last_prefix = None\n    # Prevents the common LLM error of indenting, then adding +/-, then indenting again\n    diff_spec = textwrap.dedent(diff_spec)\n    for line in diff_spec.splitlines():\n        if not line:\n            if add:\n                changes.append((remove.copy(), add.copy()))\n                remove.clear()\n                add.clear()\n                last_prefix = None\n            continue\n        if line.startswith('-'):\n            last_prefix = '-'\n            content = line[1:]\n        elif line.startswith('+'):\n            last_prefix = '+'\n            content = line[1:]\n        elif last_prefix is not None:\n            content = line\n        else:\n            errors.append(\n                f'Error: First line in a change block \"{line}\" does not start with + or -.'\n                )\n            continue\n        if last_prefix == '-':\n            remove.append(content)\n        elif last_prefix == '+':\n            add.append(content)\n    if remove or add:\n        changes.append((remove, add))\n    if not changes and not errors:\n        errors.append('Error: No valid changes found in diff spec')\n    return changes, errors\n\n\ndef _find_matching_block(current_lines, remove_lines, ignore_indentation):\n    \"\"\"Find where a block of lines matches in the current file content.\n\n    Args:\n        current_lines: List of strings representing current file content\n        remove_lines: List of strings to find in the file\n        ignore_indentation: Whether to ignore leading whitespace when matching\n\n    Returns:\n        tuple (match_found: bool, line_num: int, indent: str, match_score: float, best_index: int)\n        where:\n        - match_found indicates if an exact match was found\n        - line_num is the line where the match starts (or best partial match)\n        - indent is the indentation to preserve\n        - match_score indicates quality of best partial match (0-1)\n        - best_index is the line number of best partial match\n    \"\"\"\n    if not remove_lines:\n        return True, len(current_lines), '', 1.0, len(current_lines)\n    for i in range(len(current_lines) - len(remove_lines) + 1):\n        current_block = current_lines[i:i + len(remove_lines)]\n        if ignore_indentation:\n            match = all(c.strip() == o.strip() for c, o in zip(\n                current_block, remove_lines))\n        else:\n            match = all(c == o for c, o in zip(current_block, remove_lines))\n        if match:\n            return True, i, _get_indentation(current_lines[i]), 1.0, i\n    best_match_score = 0\n    best_match_index = 0\n    for i in range(len(current_lines) - len(remove_lines) + 1):\n        current_block = current_lines[i:i + len(remove_lines)]\n        match_score = _calculate_block_match_score(current_block,\n            remove_lines, ignore_indentation)\n        if match_score > best_match_score:\n            best_match_score = match_score\n            best_match_index = i\n    return False, best_match_index, _get_indentation(current_lines[\n        best_match_index]), best_match_score, best_match_index\n\n\ndef _get_indentation(line):\n    \"\"\"Extract the leading whitespace from a line.\"\"\"\n    return line[:len(line) - len(line.lstrip())]\n\n\ndef _adjust_indentation(lines, target_indent):\n    \"\"\"Adjust indentation of a block of lines to match target_indent.\"\"\"\n    if not lines:\n        return lines\n    non_empty_lines = [l for l in lines if l.strip()]\n    if not non_empty_lines:\n        return lines\n    min_indent = min(len(_get_indentation(l)) for l in non_empty_lines)\n    adjusted = []\n    for line in lines:\n        if not line.strip():\n            adjusted.append(line)\n        else:\n            stripped = line[min_indent:]\n            adjusted.append(target_indent + stripped)\n    return adjusted\n\n\ndef _get_context(lines, center_idx, context_size):\n    \"\"\"Get context lines around an index with line numbers.\"\"\"\n    start = max(0, center_idx - context_size)\n    end = min(len(lines), center_idx + context_size + 1)\n    return [f'{i + 1}: {line}' for i, line in enumerate(lines[start:end],\n        start)]\n\n\ndef _calculate_block_match_score(current_block, old_lines, ignore_indentation):\n    \"\"\"Calculate how well two blocks match, returning a score and matching line indices.\"\"\"\n    if ignore_indentation:\n        current_joined = ' '.join(l.strip() for l in current_block)\n        old_joined = ' '.join(l.strip() for l in old_lines)\n        current_stripped = [c.strip() for c in current_block]\n        old_stripped = [o.strip() for o in old_lines]\n    else:\n        current_joined = ' '.join(current_block)\n        old_joined = ' '.join(old_lines)\n        current_stripped = current_block\n        old_stripped = old_lines\n    exact_matches = sum(1 for c, o in zip(current_stripped, old_stripped) if\n        c == o)\n    if current_joined == old_joined:\n        return len(current_block) * 3\n    c_words = set(current_joined.split())\n    o_words = set(old_joined.split())\n    word_matches = len(c_words.intersection(o_words))\n    partial_score = 0\n    if word_matches > 0:\n        partial_score = word_matches / max(len(c_words), len(o_words))\n        if word_matches == len(c_words) and word_matches == len(o_words):\n            partial_score *= 2\n    total_score = exact_matches * 2 + partial_score\n    return total_score\n\n\ndef _has_line_number_prefix(line: str) ->bool:\n    \"\"\"Check if a string starts with a line number format (e.g., '123:' or '  123:')\n    Args:\n        line (str): The line to check\n    Returns:\n        bool: True if the line starts with a number followed by a colon\n    \"\"\"\n    stripped = line.lstrip()\n    if ':' not in stripped:\n        return False\n    prefix = stripped.split(':', 1)[0]\n    try:\n        int(prefix)\n        return True\n    except ValueError:\n        return False\n\n\ndef _strip_line_number(line: str) ->str:\n    \"\"\"Remove line number prefix if present (e.g., '123:content' or '  123:content' becomes 'content')\n    Preserves any leading whitespace before the line number.\n    Args:\n        line (str): The line to process\n    Returns:\n        str: The line with any line number prefix removed\n    \"\"\"\n    if not _has_line_number_prefix(line):\n        return line\n    whitespace = line[:len(line) - len(line.lstrip())]\n    stripped = line.lstrip()\n    content = stripped.split(':', 1)[1]\n    return whitespace + content",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
    "code_hash": "8c07ce3256cb0bf78379eb580e29fe25"
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py": {
    "name": "bots.tools.terminal_tools",
    "source": "import os, subprocess, traceback\nfrom typing import List\n\n\n\"\"\"Deb: Ah, now I understand! There's a Unicode decoding error in PowerShell when trying to handle certain bytes (0xb0) in pytest's output. This is why we're not seeing any output - it's failing silently due to the encoding error.\"\"\"\n\ndef execute_powershell(code: str, output_length_limit: str='60'):\n   \"\"\"\n   Executes PowerShell code in a stateless environment\n\n   Use when you need to run PowerShell commands and capture their output. If\n   you have other tools available, you should use this as a fallback when the\n   other tools fail. Coerces to utf-8 encoding.\n\n   Parameters:\n   - code (str): PowerShell code to execute.\n   - output_length_limit (int, optional): Maximum number of lines in the output.\n     If set, output exceeding this limit will be truncated. Default 60.\n\n   Returns command output or an error message.\n   \"\"\"\n\n   def _process_error(error):\n       error_message = f'Tool Failed: {str(error)}\\n'\n       error_message += (\n           f\"Traceback:\\n{''.join(traceback.format_tb(error.__traceback__))}\")\n       return error_message\n\n   output = ''\n   try:\n       # Wrap code to ensure proper utf-8 encoding\n       wrapped_code = f'chcp 65001 > $null; {code}'\n\n       process = subprocess.Popen(\n           ['powershell', '-Command', wrapped_code],\n           stdout=subprocess.PIPE,\n           stderr=subprocess.PIPE,\n           text=True, \n           encoding='utf-8'\n       )\n\n       stdout, stderr = process.communicate(timeout=300)\n       output = stdout\n       if stderr:\n           output += stderr\n\n   except subprocess.TimeoutExpired as e:\n       process.kill()\n       output += 'Error: Command execution timed out after 300 seconds.'\n   except Exception as e:\n       output += _process_error(e)\n\n   # Handle output length limiting\n   if output_length_limit is not None and output:\n       output_length_limit = int(output_length_limit)\n       lines = output.splitlines()\n       if len(lines) > output_length_limit:\n           truncated_lines = lines[:output_length_limit]\n           lines_omitted = len(lines) - output_length_limit\n           truncated_output = '\\n'.join(truncated_lines)\n           # Save full output to file\n           output_file = os.path.join(os.getcwd(), 'powershell_full_output.txt')\n           with open(output_file, 'w', encoding='utf-8') as f:\n               f.write(output)\n           truncated_output += (\n               f'\\n\\n{lines_omitted} lines omitted due to length limit. Full output saved to {output_file}')\n           return truncated_output\n\n   return output",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py",
    "code_hash": "2a2a670ad604bc41eeccc3bbb860d1af"
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py": {
    "name": "bots.tools.github_tools",
    "source": "import json\nfrom ghapi.all import GhApi\nimport base64\nimport os\n\n\ndef _setup():\n    \"\"\"\n    Internal function to set up the GitHub API client.\n\n    This function looks for a GitHub token in the environment variables.\n    It checks for GITHUB_TOKEN first, then GITHUB_ACCESS_TOKEN.\n    If neither is found, it raises an exception.\n\n    Returns:\n    GhApi: An instance of the GitHub API client.\n\n    Raises:\n    ValueError: If neither GITHUB_TOKEN nor GITHUB_ACCESS_TOKEN environment variable is set.\n    \"\"\"\n    token = os.environ.get('GITHUB_TOKEN') or os.environ.get(\n        'GITHUB_ACCESS_TOKEN')\n    if not token:\n        raise ValueError(\n            'Neither GITHUB_TOKEN nor GITHUB_ACCESS_TOKEN environment variable is set. Please set one of them with your GitHub Personal Access Token.'\n            )\n    return GhApi(token=token)\n\n\ndef list_repositories():\n    \"\"\"\n    List all repositories for the authenticated user.\n\n    Use when you need to get an overview of all repositories the user has access to.\n\n    Parameters:\n    None\n\n    Returns a JSON string containing an array of repository full names (owner/repo).\n    \"\"\"\n    try:\n        api = _setup()\n        repos = api.repos.list_for_authenticated_user()\n        return json.dumps([repo.full_name for repo in repos])\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef list_issues(repo_full_name, state='open'):\n    \"\"\"\n    List issues in a repository.\n\n    Use when you need to get an overview of issues in a specific repository.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - state (str): The state of issues to list ('open', 'closed', or 'all', default is 'open').\n\n    Returns a JSON string containing an array of issues with their number, title, and state.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issues = api.issues.list_for_repo(owner=owner, repo=repo, state=state)\n        return json.dumps([{'number': issue.number, 'title': issue.title,\n            'state': issue.state} for issue in issues])\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef create_issue(repo_full_name, title, body):\n    \"\"\"\n    Create a new issue in a repository.\n\n    Use when you need to open a new issue in a specific repository.\n\n    If you have access to this tool, you may use it to report issues with itself\n    and any other tools (tool failures only) to: https://github.com/benbuzz790/bots.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - title (str): The title of the issue.\n    - body (str): The body content of the issue.\n\n    Returns a JSON string containing the issue number and URL or an error message if unauthorized.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        repos = json.loads(list_repositories())\n        if not any(repo == repo_full_name for repo in repos):\n            return (\n                f'Error: Not authorized to create issues in {repo_full_name}. Repository must be in your list of accessible repositories.'\n                )\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.create(owner=owner, repo=repo, title=title, body\n            =body)\n        return json.dumps({'number': issue.number, 'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef get_issue(repo_full_name, issue_number):\n    \"\"\"\n    Get detailed information about a specific issue.\n\n    Use when you need to retrieve full details of a particular issue.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - issue_number (int): The number of the issue to retrieve.\n\n    Returns a JSON string containing the issue details including title, body, state, labels, and comments count.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.get(owner=owner, repo=repo, issue_number=\n            issue_number)\n        return json.dumps({'number': issue.number, 'title': issue.title,\n            'body': issue.body, 'state': issue.state, 'labels': [label.name for\n            label in issue.labels], 'comments': issue.comments,\n            'created_at': issue.created_at, 'updated_at': issue.updated_at,\n            'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef update_issue(repo_full_name, issue_number, **kwargs):\n    \"\"\"\n    Update an existing issue.\n\n    Use when you need to modify an issue's properties like title, body, or state.\n\n    Parameters:\n    - repo_full_name (str or dict): The full name of the repository in the format \"owner/repo\" or {\"repo\": \"owner/repo\"}.\n    - issue_number (int): The number of the issue to update.\n    - **kwargs: Properties to update. Can include:\n        - title (str): New title for the issue\n        - body (str): New body content\n        - state (str): New state ('open' or 'closed')\n        - labels (list): List of label names\n\n    Returns a JSON string containing the updated issue information.\n    \"\"\"\n    try:\n        api = _setup()\n        repo_full_name = _normalize_repo_name(repo_full_name)\n        owner, repo = repo_full_name.split('/')\n        issue = api.issues.update(owner=owner, repo=repo, issue_number=\n            issue_number, **kwargs)\n        return json.dumps({'number': issue.number, 'title': issue.title,\n            'state': issue.state, 'url': issue.html_url})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef get_github_user_info():\n    \"\"\"\n    Get information about the authenticated user.\n\n    Use when you need to retrieve details about the current user's GitHub account.\n\n    Parameters:\n    None\n\n    Returns a JSON string containing user information (login, name, email, public repository count).\n    \"\"\"\n    try:\n        api = _setup()\n        user = api.users.get_authenticated()\n        return json.dumps({'login': user.login, 'name': user.name, 'email':\n            user.email, 'public_repos': user.public_repos})\n    except Exception as e:\n        return f'Error: {str(e)}'\n\n\ndef _normalize_repo_name(repo_full_name):\n    \"\"\"\n    Helper function to normalize repository name input.\n    Handles both string format and JSON object format.\n\n    Parameters:\n    - repo_full_name: Can be one of:\n        - string in format \"owner/repo\"\n        - dict with 'repo' key\n        - JSON string representing dict with 'repo' key\n\n    Returns:\n    str: Normalized repository name in \"owner/repo\" format\n    \"\"\"\n    if isinstance(repo_full_name, dict):\n        if not repo_full_name:\n            raise ValueError('Empty dictionary provided')\n        if 'repo' not in repo_full_name:\n            raise ValueError(\"Dictionary input must contain 'repo' key\")\n        repo_name = repo_full_name['repo']\n        if not isinstance(repo_name, str):\n            raise ValueError('Repository name must be a string')\n        if '/' not in repo_name:\n            raise ValueError(\"Repository name must be in 'owner/repo' format\")\n        return repo_name\n    if not isinstance(repo_full_name, str):\n        raise ValueError('Input must be a string or dictionary')\n    if repo_full_name.strip().startswith('{'):\n        try:\n            parsed = json.loads(repo_full_name)\n            if not isinstance(parsed, dict):\n                raise ValueError('Parsed JSON must be a dictionary')\n            if 'repo' not in parsed:\n                raise ValueError(\n                    \"Parsed JSON dictionary must contain 'repo' key\")\n            repo_name = parsed['repo']\n            if not isinstance(repo_name, str):\n                raise ValueError('Repository name must be a string')\n            if '/' not in repo_name:\n                raise ValueError(\n                    \"Repository name must be in 'owner/repo' format\")\n            return repo_name\n        except json.JSONDecodeError:\n            pass\n    if not repo_full_name:\n        raise ValueError('Empty string provided')\n    if '/' not in repo_full_name:\n        raise ValueError(\"Repository name must be in 'owner/repo' format\")\n    owner, repo = repo_full_name.split('/')\n    if not owner or not repo:\n        raise ValueError('Both owner and repo must be non-empty')\n    return repo_full_name",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
    "code_hash": "69ff2574590a24a7b59d34d47c1057c8"
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\experiments\\debug_bot_tools.py": {
    "name": "dynamic_module_5a4535b039d5c183a5c854cc34af7fbb",
    "source": "import inspect\nimport traceback\nimport datetime as DT\nimport subprocess\nimport ast\nimport astor\nimport os\nimport textwrap\n\n\nclass NoLineBreakSourceGenerator(astor.SourceGenerator):\n    \"\"\"Custom source generator that prevents line breaks in the output.\"\"\"\n\n    def __init__(self, indent_with=' ' * 4, add_line_information=False,\n        pretty_string=None, **kwargs):\n        super().__init__(indent_with=indent_with, add_line_information=\n            add_line_information, pretty_string=pretty_string, **kwargs)\n        self.max_line_length = float('inf')\n\n\ndef _to_source(node):\n    \"\"\"Convert AST node to source code without line breaks.\"\"\"\n    return astor.to_source(node, source_generator_class=\n        NoLineBreakSourceGenerator)\n\n\nclass NodeTransformerWithAsyncSupport(ast.NodeTransformer):\n    \"\"\"Base class for AST transformers that need to handle both sync and async functions.\"\"\"\n\n    def __init__(self):\n        self.success = False\n\n    def visit_FunctionDef(self, node):\n        return self._handle_function(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        return self._handle_function(node)\n\n    def _handle_function(self, node):\n        \"\"\"Override this method in subclasses to implement specific transformation logic\"\"\"\n        raise NotImplementedError\n\n\nclass FunctionReplacer(NodeTransformerWithAsyncSupport):\n\n    def __init__(self, new_func_node):\n        super().__init__()\n        self.new_func_node = new_func_node\n\n    def _handle_function(self, node):\n        if node.name == self.new_func_node.name:\n            self.success = True\n            return self.new_func_node\n        return node\n\n\nclass MethodAdder(NodeTransformerWithAsyncSupport):\n\n    def __init__(self, class_name, new_method_node):\n        super().__init__()\n        self.class_name = class_name\n        self.new_method_node = new_method_node\n\n    def visit_ClassDef(self, node):\n        if node.name == self.class_name:\n            self.success = True\n            node.body.append(self.new_method_node)\n            return node\n        return node\n\n    def _handle_function(self, node):\n        return node\n\n\ndef _add_imports(file_path: str, code: str) ->str:\n    \"\"\"\n    Adds multiple import statements to a Python file.\n    Creates the file if it doesn't exist.\n    Avoids adding duplicate imports.\n\n    Handles various import formats including:\n    - Simple imports: import os\n    - From imports: from typing import List\n    - Multi-line parenthesized imports:\n      from module import (\n          thing1,\n          thing2\n      )\n\n    Parameters:\n    - file_path (str): The path to the file where the imports will be added\n    - code (str): Import statements, which can include parenthesized multi-line imports\n        Example:\n        '''\n        import os\n        from typing import List\n        from module import (\n            thing1,\n            thing2\n        )\n        '''\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        lines = code.strip().split('\\n')\n        import_blocks = []\n        current_block = []\n        in_parentheses = False\n        for line in lines:\n            stripped = line.strip()\n            if not stripped:\n                continue\n            if '(' in stripped and not stripped.endswith(')'):\n                in_parentheses = True\n                current_block.append(stripped)\n            elif ')' in stripped and in_parentheses:\n                in_parentheses = False\n                current_block.append(stripped)\n                import_blocks.append('\\n'.join(current_block))\n                current_block = []\n            elif in_parentheses:\n                current_block.append(stripped)\n            elif current_block:\n                current_block.append(stripped)\n            else:\n                import_blocks.append(stripped)\n        if current_block:\n            import_blocks.append('\\n'.join(current_block))\n        new_import_nodes = []\n        for stmt in import_blocks:\n            try:\n                node = ast.parse(_clean(stmt)).body[0]\n                if not isinstance(node, (ast.Import, ast.ImportFrom)):\n                    return _process_error(ValueError(\n                        f'Invalid import statement: {stmt}'))\n                new_import_nodes.append(node)\n            except Exception as e:\n                return _process_error(ValueError(\n                    f'Error parsing import statement \"{stmt}\": {str(e)}'))\n        try:\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error reading file {abs_path}: {str(e)}'))\n        if not content.strip():\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write('\\n'.join(import_blocks) + '\\n')\n            return (\n                f\"{len(import_blocks)} imports have been added to new file '{abs_path}'.\"\n                )\n        try:\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error parsing the file {abs_path}: {str(e)}'))\n        added_imports = []\n        existing_imports = []\n\n        def normalize_import(node):\n            \"\"\"Helper to normalize import node to string for comparison\"\"\"\n            return _to_source(node).strip().replace(' ', '')\n        for new_node in new_import_nodes:\n            new_stmt_normalized = normalize_import(new_node)\n            is_duplicate = False\n            for existing_node in tree.body:\n                if isinstance(existing_node, (ast.Import, ast.ImportFrom)):\n                    if normalize_import(existing_node) == new_stmt_normalized:\n                        existing_imports.append(_to_source(new_node).strip())\n                        is_duplicate = True\n                        break\n            if not is_duplicate:\n                added_imports.append(_to_source(new_node).strip())\n        if added_imports:\n            last_import_idx = -1\n            for i, node in enumerate(tree.body):\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    last_import_idx = i\n            for node in new_import_nodes:\n                if _to_source(node).strip() in added_imports:\n                    tree.body.insert(last_import_idx + 1, node)\n                    last_import_idx += 1\n            try:\n                updated_content = _to_source(tree)\n                with open(abs_path, 'w', encoding='utf-8') as file:\n                    file.write(updated_content)\n            except Exception as e:\n                return _process_error(e)\n        result_parts = []\n        if added_imports:\n            result_parts.append(\n                f\"Added {len(added_imports)} new imports to '{abs_path}'\")\n        if existing_imports:\n            result_parts.append(\n                f'Found {len(existing_imports)} existing imports')\n        if not result_parts:\n            raise ValueError('No valid import statements found')\n        return '. '.join(result_parts) + '.'\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _remove_import(file_path: str, import_to_remove: str) ->str:\n    \"\"\"\n    Removes an import statement from a Python file.\n    \n    Parameters:\n    - file_path (str): The path to the file to modify\n    - import_to_remove (str): The import statement to remove (e.g., \"import os\" or \"from typing import List\")\n        Must match the existing import statement exactly.\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    if not os.path.exists(file_path):\n        return _process_error(ValueError(f'File {file_path} does not exist'))\n    try:\n        remove_node = ast.parse(import_to_remove).body[0]\n        if not isinstance(remove_node, (ast.Import, ast.ImportFrom)):\n            return _process_error(ValueError(\n                'Provided statement is not a valid import'))\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing import statement: {str(e)}'))\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        tree = ast.parse(content)\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing the file {file_path}: {str(e)}'))\n    original_length = len(tree.body)\n    new_body = []\n    found = False\n    for node in tree.body:\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\n            node_str = _to_source(node).strip()\n            if node_str == import_to_remove:\n                found = True\n                continue\n        new_body.append(node)\n    if not found:\n        return f\"Import '{import_to_remove}' not found in '{file_path}'.\"\n    tree.body = new_body\n    try:\n        updated_content = _to_source(tree)\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(updated_content)\n    except Exception as e:\n        return _process_error(e)\n    return f\"Import '{import_to_remove}' has been removed from '{file_path}'.\"\n\n\ndef _replace_import(file_path: str, old_import: str, new_import: str) ->str:\n    \"\"\"\n    Replaces an existing import statement in a Python file.\n    \n    Parameters:\n    - file_path (str): The path to the file to modify\n    - old_import (str): The existing import statement to replace\n    - new_import (str): The new import statement\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    if not os.path.exists(file_path):\n        return _process_error(ValueError(f'File {file_path} does not exist'))\n    try:\n        old_node = ast.parse(_clean(old_import)).body[0]\n        new_node = ast.parse(_clean(new_import)).body[0]\n        if not isinstance(old_node, (ast.Import, ast.ImportFrom)\n            ) or not isinstance(new_node, (ast.Import, ast.ImportFrom)):\n            return _process_error(ValueError(\n                'Both statements must be valid imports'))\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing import statements: {str(e)}'))\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        tree = ast.parse(content)\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing the file {file_path}: {str(e)}'))\n    found = False\n    for i, node in enumerate(tree.body):\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\n            node_str = _to_source(node).strip()\n            if node_str == old_import:\n                tree.body[i] = new_node\n                found = True\n                break\n    if not found:\n        return f\"Import '{old_import}' not found in '{file_path}'.\"\n    try:\n        updated_content = _to_source(tree)\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(updated_content)\n    except Exception as e:\n        return _process_error(e)\n    return (\n        f\"Import '{old_import}' has been updated to '{new_import}' in '{file_path}'.\"\n        )\n\n\ndef _add_class(file_path: str, class_def: str) ->str:\n    \"\"\"\n    Adds a new class definition to an existing Python file.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file where the new class will be added\n    - class_def (str): The new class definition as a string\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(class_def))\n            new_class_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    _add_imports(file_path, _to_source(node).strip())\n                elif isinstance(node, ast.ClassDef):\n                    new_class_node = node\n            if new_class_node is None:\n                return _process_error(ValueError(\n                    'No class definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n        tree.body.append(new_class_node)\n        try:\n            updated_content = _to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return f\"Class '{new_class_node.name}' has been added to '{abs_path}'.\"\n    except Exception as e:\n        return _process_error(e)\n\n\ndef replace_class(file_path: str, new_class_def: str, old_class_name: str=None\n    ) ->str:\n    \"\"\"\n    Replaces a class definition in a file with a new class definition.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_class_def (str): The new class definition\n    - old_class_name (str, optional): The name of the class to replace\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_class_def))\n            new_class_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    _add_imports(file_path, _to_source(node).strip())\n                elif isinstance(node, ast.ClassDef):\n                    new_class_node = node\n                    if old_class_name is None:\n                        old_class_name = node.name\n            if new_class_node is None:\n                return _process_error(ValueError(\n                    'No class definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n\n\n        class ClassReplacer(NodeTransformerWithAsyncSupport):\n\n            def visit_ClassDef(self, node):\n                if node.name == old_class_name:\n                    self.success = True\n                    return new_class_node\n                return node\n\n            def _handle_function(self, node):\n                return node\n        transformer = ClassReplacer()\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            tree.body.append(new_class_node)\n        try:\n            updated_content = _to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        action = 'replaced in' if transformer.success else 'added to'\n        return f\"Class '{new_class_node.name}' has been {action} '{abs_path}'.\"\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _add_function_to_class(file_path: str, class_name: str, new_method_def: str\n    ) ->str:\n    \"\"\"\n    Adds one or more methods to an existing class in a Python file.\n    Creates the file and class if they don't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - class_name (str): The name of the class to modify\n    - new_method_def (str): One or more method definitions as a string\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_method_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                _add_imports(file_path, _to_source(node).strip())\n        found_method = False\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_method = True\n                method_source = _to_source(node)\n                result = _add_single_function_to_class(file_path,\n                    class_name, method_source)\n                messages.append(result)\n        if not found_method:\n            return _process_error(ValueError(\n                'No method definitions found in provided code'))\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _add_function_to_file(file_path: str, new_function_def: str, class_name:\n    str=None) ->str:\n    \"\"\"\n    Adds one or more function definitions to an existing Python file.\n    Creates the file if it doesn't exist.\n\n    When adding complex code blocks:\n    - Imports are moved to the top of the file\n    - Functions are added in order of appearance\n    - Non-function code (assignments, if blocks, etc.) is preserved but may be reordered\n    - Comments are not preserved (limitation of AST)\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_function_def (str): One or more function definitions as a string\n    - class_name (str, optional): If provided, add functions to this class\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_function_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                _add_imports(file_path, _to_source(node).strip())\n        found_function = False\n        remaining_nodes = []\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_function = True\n                function_source = _to_source(node)\n                if class_name:\n                    result = _add_function_to_class(file_path, class_name,\n                        function_source)\n                else:\n                    result = _add_single_function_to_file(file_path,\n                        function_source)\n                messages.append(result)\n            elif not isinstance(node, (ast.Import, ast.ImportFrom)):\n                remaining_nodes.append(node)\n        if not found_function:\n            return _process_error(ValueError(\n                'No function definitions found in provided code'))\n        if remaining_nodes:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            existing_tree = ast.parse(content)\n            existing_tree.body.extend(remaining_nodes)\n            updated_content = _to_source(existing_tree)\n            with open(file_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n            messages.append(\n                f'Added {len(remaining_nodes)} additional code blocks')\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef replace_function(file_path: str, new_function_def: str, class_name: str\n    =None) ->str:\n    \"\"\"\n    Replaces one or more function definitions in a file with new function definitions.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_function_def (str): One or more function definitions as a string\n    - class_name (str, optional): If provided, only replace functions within this class\n\n    Returns a confirmation message or an error message.\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_function_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                _add_imports(file_path, _to_source(node).strip())\n        found_function = False\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_function = True\n                function_source = _to_source(node)\n                result = _replace_single_function(file_path,\n                    function_source, class_name)\n                messages.append(result)\n        if not found_function:\n            return _process_error(ValueError(\n                'No function definitions found in provided code'))\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _execute_python_code(code: str, timeout: int=300) ->str:\n    \"\"\"\n    Executes python code in a stateless environment with cross-platform timeout handling.\n\n    Parameters:\n    - code (str): Syntactically correct python code\n    - timeout (int): Maximum execution time in seconds (default: 300)\n\n    Returns stdout or an error message.\n    \"\"\"\n\n    def create_wrapper_ast():\n        wrapper_code = textwrap.dedent(\n            \"\"\"\n            import os\n            import sys\n            import traceback\n            import time\n            sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n            if sys.platform == 'win32':\n                import codecs\n                sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')\n                sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')\n\n            def main():\n                pass  # Placeholder for user code\n\n            if __name__ == '__main__':\n                try:\n                    main()\n                except Exception as error:\n                    print(f\"An error occurred: {str(error)}\", file=sys.stderr)\n                    traceback.print_exc(file=sys.stderr)\n                    sys.exit(1)\n            \"\"\"\n            )\n        return ast.parse(wrapper_code)\n\n    def insert_code_into_wrapper(wrapper_ast, code_ast, timeout_value):\n        main_func = next(node for node in wrapper_ast.body if isinstance(\n            node, ast.FunctionDef) and node.name == 'main')\n        main_func.body = code_ast.body\n        return wrapper_ast\n    try:\n        if not isinstance(timeout, int) or timeout <= 0:\n            return _process_error(ValueError(\n                'Timeout must be a positive integer'))\n        try:\n            code_ast = ast.parse(_clean(code))\n        except SyntaxError as e:\n            return f'SyntaxError: {str(e)}'\n        wrapper_ast = create_wrapper_ast()\n        combined_ast = insert_code_into_wrapper(wrapper_ast, code_ast, timeout)\n        final_code = _to_source(combined_ast)\n    except Exception as e:\n        return _process_error(e)\n    package_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    scripts_dir = os.path.join(package_root, 'scripts')\n    if not os.path.exists(scripts_dir):\n        os.makedirs(scripts_dir)\n    temp_file_name = os.path.join(scripts_dir, f'temp_script_{os.getpid()}.py')\n    try:\n        with open(temp_file_name, 'w', encoding='utf-8') as temp_file:\n            temp_file.write(final_code)\n            temp_file.flush()\n            os.fsync(temp_file.fileno())\n        env = os.environ.copy()\n        env['PYTHONIOENCODING'] = 'utf-8'\n        process = subprocess.Popen(['python', temp_file_name], stdout=\n            subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding=\n            'utf-8', creationflags=subprocess.CREATE_NO_WINDOW if os.name ==\n            'nt' else 0, env=env)\n        try:\n            stdout, stderr = process.communicate(timeout=timeout)\n            if process.returncode != 0:\n                return stderr or 'Process failed with no error message'\n            return stdout + stderr\n        except subprocess.TimeoutExpired:\n            process.terminate()\n            try:\n                process.wait(timeout=1)\n            except subprocess.TimeoutExpired:\n                process.kill()\n            return f'Error: Code execution timed out after {timeout} seconds'\n    except Exception as e:\n        return _process_error(e)\n    finally:\n        try:\n            if os.path.exists(temp_file_name):\n                os.remove(temp_file_name)\n        except Exception:\n            pass\n\n\ndef _get_py_interface(file_path: str) ->str:\n    \"\"\"\n    Outputs a string showing all class and function definitions including docstrings.\n\n    Parameters:\n    - file_path (str): The path to the Python file to analyze\n\n    Returns a string containing all class and function definitions with their docstrings.\n    \"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        tree = ast.parse(content)\n        interface = []\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                type_name = 'class' if isinstance(node, ast.ClassDef\n                    ) else 'def'\n                if isinstance(node, ast.AsyncFunctionDef):\n                    type_name = 'async def'\n                definition = f'{type_name} {node.name}'\n                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    args = [arg.arg for arg in node.args.args]\n                    definition += f\"({', '.join(args)})\"\n                interface.append(definition)\n                docstring = ast.get_docstring(node)\n                if docstring:\n                    interface.append(f'    \"\"\"{docstring}\"\"\"')\n                interface.append('')\n        return '\\n'.join(interface)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _clean(code: str) ->str:\n    \"\"\"Clean and dedent code before parsing.\n    \n    Args:\n        code (str): The code to clean\n        \n    Returns:\n        str: The cleaned and dedented code\n    \"\"\"\n    return textwrap.dedent(code).strip()\n\n\ndef _process_error(error: Exception) ->str:\n    \"\"\"Format error message with traceback.\"\"\"\n    error_message = f'Tool Failed: {str(error)}\\n'\n    error_message += (\n        f\"Traceback:\\n{''.join(traceback.format_tb(error.__traceback__))}\")\n    return error_message\n\n\ndef _make_file(file_path: str) ->str:\n    \"\"\"\n    Creates a file and its parent directories if they don't exist.\n    Converts relative paths to absolute paths.\n    \n    Parameters:\n    - file_path (str): The path to the file to be created\n    \n    Returns:\n    - str: The absolute path to the file\n    \n    Raises:\n    - ValueError: If there's an error creating the file or directories,\n                 or if the file_path is empty\n    \"\"\"\n    if not file_path:\n        raise ValueError('File path cannot be empty')\n    abs_path = os.path.abspath(file_path)\n    dir_path = os.path.dirname(abs_path)\n    if dir_path:\n        try:\n            os.makedirs(dir_path, exist_ok=True)\n        except Exception as e:\n            raise ValueError(f'Error creating directories {dir_path}: {str(e)}'\n                )\n    if not os.path.exists(abs_path):\n        try:\n            with open(abs_path, 'w', encoding='utf-8') as f:\n                f.write('')\n        except Exception as e:\n            raise ValueError(f'Error creating file {abs_path}: {str(e)}')\n    return abs_path\n\n\ndef _add_single_function_to_class(file_path: str, class_name: str,\n    new_method_def: str) ->str:\n    \"\"\"Adds a single method to a class.\"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_method_def))\n            new_method_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    _add_imports(file_path, _to_source(node).strip())\n                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    new_method_node = node\n            if new_method_node is None:\n                return _process_error(ValueError(\n                    'No method definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            if not content.strip():\n                content = f'class {class_name}:\\n    pass\\n'\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n        transformer = MethodAdder(class_name, new_method_node)\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            return _process_error(ValueError(\n                f\"Class '{class_name}' not found in the file.\"))\n        try:\n            updated_content = _to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return (\n            f\"Method '{new_method_node.name}' has been added to class '{class_name}' in '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _add_single_function_to_file(file_path: str, new_function_def: str) ->str:\n    \"\"\"Adds a single function and preserves all code blocks, including any code following the function.\"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_function_def))\n            new_func_node = None\n            found_func = False\n            new_nodes = []\n            for node in new_tree.body:\n                if not found_func and isinstance(node, (ast.FunctionDef,\n                    ast.AsyncFunctionDef)):\n                    new_func_node = node\n                    found_func = True\n                elif found_func:\n                    new_nodes.append(node)\n            if not new_func_node:\n                return _process_error(ValueError(\n                    'No function definition found in provided code'))\n        except Exception as e:\n            return _process_error(ValueError(f'Error in code: {str(e)}'))\n        with open(abs_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        if not content.strip():\n            try:\n                with open(abs_path, 'w', encoding='utf-8') as file:\n                    file.write(_to_source(new_tree))\n                return (\n                    f\"Code with function '{new_func_node.name}' has been added to new file '{abs_path}'.\"\n                    )\n            except Exception as e:\n                return _process_error(e)\n        try:\n            existing_tree = ast.parse(content)\n            combined_body = []\n            imports = []\n            for node in (existing_tree.body + new_tree.body):\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    imports.append(node)\n            combined_body.extend(imports)\n            for node in existing_tree.body:\n                if not isinstance(node, (ast.Import, ast.ImportFrom)):\n                    combined_body.append(node)\n            combined_body.append(new_func_node)\n            combined_body.extend(new_nodes)\n            combined_tree = ast.Module(body=combined_body, type_ignores=[])\n            updated_content = _to_source(combined_tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return (\n            f\"Code with function '{new_func_node.name}' has been added to '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _replace_single_function(file_path: str, new_function_def: str,\n    class_name: str=None) ->str:\n    \"\"\"Replaces a single function in a file, optionally within a specific class.\n    \n    Args:\n        file_path: Path to the file to modify\n        new_function_def: The new function definition\n        class_name: If provided, only replace within this class\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_function_def))\n            new_func_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    _add_imports(file_path, _to_source(node).strip())\n                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    new_func_node = node\n            if new_func_node is None:\n                return _process_error(ValueError(\n                    'No function definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n\n\n        class ClassScopedFunctionReplacer(ast.NodeTransformer):\n\n            def __init__(self, new_func_node, target_class=None):\n                self.new_func_node = new_func_node\n                self.target_class = target_class\n                self.success = False\n                self.in_target_class = False\n\n            def visit_ClassDef(self, node):\n                if self.target_class is None or node.name == self.target_class:\n                    old_in_target_class = self.in_target_class\n                    self.in_target_class = True\n                    node = self.generic_visit(node)\n                    self.in_target_class = old_in_target_class\n                return node\n\n            def visit_FunctionDef(self, node):\n                if node.name == self.new_func_node.name:\n                    if self.target_class is None or self.in_target_class:\n                        self.success = True\n                        return self.new_func_node\n                return node\n\n            def visit_AsyncFunctionDef(self, node):\n                return self.visit_FunctionDef(node)\n        transformer = ClassScopedFunctionReplacer(new_func_node, class_name)\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            if class_name:\n                return _process_error(ValueError(\n                    f\"Function '{new_func_node.name}' not found in class '{class_name}'\"\n                    ))\n            tree.body.append(new_func_node)\n        try:\n            updated_content = _to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        context = f\"in class '{class_name}'\" if class_name else 'in file'\n        action = 'replaced' if transformer.success else 'added'\n        return (\n            f\"Function '{new_func_node.name}' has been {action} {context} '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\experiments\\debug_bot_tools.py",
    "code_hash": "a85b42afb51374e1c516afa87f236d12"
   }
  },
  "function_paths": {
   "diff_edit": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "view": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "view_dir": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "execute_powershell": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py",
   "create_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "get_github_user_info": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "get_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "list_issues": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "list_repositories": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "update_issue": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\github_tools.py",
   "replace_class": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\experiments\\debug_bot_tools.py",
   "replace_function": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\experiments\\debug_bot_tools.py"
  }
 },
 "autosave": false,
 "tool_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\experiments\\debug_bot_tools.py",
 "bot_class": "AnthropicBot"
}